# Getting data from APIs

These are the tasks for the week:

**NOTE: if you call APIs too quickly (most likely due to a coding error, where you call the API multiple times in a row) you might get rate limited or banned for a while.**

## Parsing XML

- Get familiar with **requests**, and **beautifulsoup4** libraries.
- Use them to get the RSS feeds from an online journal of your choice
- Create a basic news aggregator of some sort and push it to GIT

## Parsing JSON

- Find a JSON weather API and get the weather forecast on Budapest
- Create a basic weather widget and push it to GIT
- ❓ Question: Explain the differences between XML and JSON 

## Connect to Twitter JSON API

- Register to get developer authentication to use the Twitter API
- Write code in Python that searches for certain #hashtags on Twitter using an existing library

## Connect to Wikipedia API

- Make a Wikipedia crawler that lets users search for terms without browsing Wikipedia
- Write code that returns the short summary of a Wikipedia article
- Write code that returns basic information (usually shown in the boxes, next to the article) on a Wikipedia article

## In case you are done with all of these, you can

- ❓ Question: Explain the differences in crawling data in different languages (Hungarian VS English)
- ⚡ Extra task: Surprise me by connecting to a (preferrably social media) API of your choice with your own code, instead of using existing libraries. 
